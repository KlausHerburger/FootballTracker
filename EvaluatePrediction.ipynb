{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "649af7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b2f0f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load model\n",
    "model = load_model('Models/ClassifyLocations.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a530b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredictions(videoNr, xsplit, ysplit):\n",
    "    \"\"\" Gets predictions from the model\n",
    "    Args:\n",
    "      videoNr: Number of the video to get the predictions for \n",
    "      xsplit: Number of discrete grid splits in x direction\n",
    "      ysplit: Number of discrete gird splits in y direction\n",
    "      \n",
    "    Returns:\n",
    "      Predicted locations for all image frames in the given video\n",
    "    \"\"\"\n",
    "    \n",
    "    # Load and normalize original images\n",
    "    images = np.load('ImageFrames/Images_Video' + str(videoNr) + '_10.npy') \n",
    "    images = images/images.max() \n",
    "    \n",
    "    # Load and normalize dilated and thresholded images\n",
    "    imagesDT = np.load('ImageFrames/Images_DilatedThresholded_Video' + str(videoNr) + '_20.npy') \n",
    "    imagesDT = imagesDT/imagesDT.max() \n",
    "    \n",
    "    # Load and normalize annotations for last ten locations\n",
    "    annotations = np.load('AnnotationFiles/Annotations_LastTenLocations_Video' + str(videoNr) + '_' + str(xsplit) +'_' + str(ysplit) +'_10.npy')\n",
    "    annotations = annotations/annotations.max()\n",
    "    \n",
    "    # Get prediction from model and choose the location with highest probability\n",
    "    predictions = model.predict([images, imagesDT[..., np.newaxis], annotations])\n",
    "    predictedLocations = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    return predictedLocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8aaa012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculateMAE(predictions, annotations, xsplit, ysplit):  \n",
    "    \"\"\" Calculates the mean absolute error between the position predicted by the model and the true position of the ball\n",
    "    Args:\n",
    "      predictions: Predicted locations for all image frames \n",
    "      annotations: True locations for all image frames\n",
    "      xsplit: Number of discrete grid splits in x direction\n",
    "      ysplit: Number of discrete gird splits in y direction\n",
    "      \n",
    "    Returns:\n",
    "      Mean absolute error\n",
    "    \"\"\"\n",
    "    \n",
    "    sumError = 0\n",
    "    xmax = 1920\n",
    "    ymax = 1088\n",
    "    for i in range(len(predictions)):\n",
    "        prediction = predictions[i]\n",
    "        \n",
    "        # Calculate predicted position of the ball (x,y) as middle point of the grid section that was predicted, if a ball was predicted\n",
    "        if prediction!=0:\n",
    "            xstart = int(xmax/xsplit*((prediction-1)%xsplit))\n",
    "            xend = int(xstart + xmax/xsplit)\n",
    "            ystart = int(ymax/ysplit*np.floor((prediction-1)/xsplit))\n",
    "            yend = int(ystart + ymax/ysplit)\n",
    "            x = xstart+(xend-xstart)/2\n",
    "            y = ystart+(yend-ystart)/2\n",
    "            predictedOutput = np.array([x, y])\n",
    "            \n",
    "        # Sets predicted position to (0,0), if no ball was predicted in an image frame\n",
    "        else:\n",
    "            predictedOutput = np.array([0, 0])\n",
    "            \n",
    "        # Set true position to (0,0), if no ball is in the image frame, else set postion \n",
    "        if -1 in annotations[i]:\n",
    "            trueOutput = np.array([0, 0])\n",
    "        else:\n",
    "            trueOutput = annotations[i]\n",
    "\n",
    "        # Calcuate euclidean distance between predicted and true position and add to totol error  \n",
    "        error = np.linalg.norm(predictedOutput-trueOutput)\n",
    "        sumError = sumError + error\n",
    "        \n",
    "    return sumError/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e462d063",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateVideos(videoNrs, xsplit, ysplit, printSingleVideos):  \n",
    "    \"\"\" Evaluates MAE, Precision, Recall and F1-Score for given videos\n",
    "    Args:\n",
    "      videosNrs: Numbers of the videos to evaluate\n",
    "      xsplit: Number of discrete grid splits in x direction\n",
    "      ysplit: Number of discrete gird splits in y direction\n",
    "      printSingleVideos: Flag that defines if stats for all single Videos should be printed\n",
    "      \n",
    "    Returns:\n",
    "      Total Mean absolute error\n",
    "      Total Precision\n",
    "      Total Recall\n",
    "      Total F1-Score\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get Predictions and annotations for all videos and calculate the individual MAEs for each videos\n",
    "    allPredictions = []\n",
    "    allAnnotationsRegression = []\n",
    "    allAnnotationsClassification = []\n",
    "    allMae = []\n",
    "    for videoNr in videoNrs:\n",
    "        predictions = getPredictions(videoNr,xsplit,ysplit)\n",
    "        allPredictions.append(predictions)\n",
    "        annotationsRegression = np.load('AnnotationFiles/Annotations_BallPosition_Video' + str(videoNr) + '.npy')\n",
    "        allAnnotationsRegression.append(allAnnotationsRegression)\n",
    "        mae = calculateMAE(predictions, annotationsRegression, xsplit, ysplit)\n",
    "        allMae.append(mae)\n",
    "        annotationsClassification = np.load('AnnotationFiles/Annotations_ClassifyLocations_Video' + str(videoNr) + '_' + str(xsplit) +'_' + str(ysplit) +'_10.npy')\n",
    "        allAnnotationsClassification.append(annotationsClassification)\n",
    "        accuracy = accuracy_score(annotationsClassification, predictions)\n",
    "        if(printSingleVideos):\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(annotationsClassification, predictions, average='weighted')\n",
    "            print('videoNr', videoNr)\n",
    "            print('mae', mae)\n",
    "            print('accuracy', accuracy)\n",
    "            print('precision', precision)\n",
    "            print('recall', recall)\n",
    "            print('f1-score', f1)\n",
    "\n",
    "    # Merge the predictions and annotations for all videos to calculate stats for all videos \n",
    "    annotationsPredictions = np.zeros((18000,1), dtype=np.uint32)\n",
    "    annotationsRegressionAllVideos = np.zeros((18000,2))\n",
    "    annotationsClassifyLocAllVideos = np.zeros((18000,1), dtype=np.uint32)\n",
    "    maeAllVideos = 0\n",
    "    shape=0\n",
    "    sumAccuracy = 0\n",
    "    for videoNr in videoNrs:\n",
    "        annosClass = allAnnotationsClassification[videoNr-1]\n",
    "        annotationsClassifyLocAllVideos[shape:shape+annosClass.shape[0]] = annosClass\n",
    "        annotationsRegressionAllVideos[shape:shape+annosClass.shape[0]] = annotationsRegressionAllVideos[videoNr-1]\n",
    "        annotationsPredictions[shape:shape+annosClass.shape[0]] = allPredictions[videoNr-1][...,np.newaxis]\n",
    "        accuracy = accuracy_score(allAnnotationsClassification[videoNr-1], allPredictions[videoNr-1])\n",
    "        sumAccuracy = sumAccuracy + accuracy\n",
    "        maeAllVideos = maeAllVideos + allMae[videoNr-1]\n",
    "        shape = shape + annosClass.shape[0]\n",
    "    annotationsClassifyLocAllVideos = annotationsClassifyLocAllVideos[0:shape]\n",
    "    annotationsRegressionAllVideos = annotationsRegressionAllVideos[0:shape]\n",
    "    annotationsPredictions = annotationsPredictions[0:shape]\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(annotationsClassifyLocAllVideos, annotationsPredictions, average='weighted')\n",
    "    print('Total')\n",
    "    print('mae', maeAllVideos/len(videoNrs))\n",
    "    print('accuracy', sumAccuracy/len(videoNrs))\n",
    "    print('precision', precision)\n",
    "    print('recall', recall)\n",
    "    print('f1-score', f1)\n",
    "    \n",
    "    return maeAllVideos/len(videoNrs), sumAccuracy/len(videoNrs), precision, recall, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a289206",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "videoNr 1\n",
      "mae 22.43132783212297\n",
      "accuracy 0.9419613075383589\n",
      "precision 0.9315600328618071\n",
      "recall 0.9419613075383589\n",
      "f1-score 0.9307102661362081\n",
      "videoNr 2\n",
      "mae 19.212608074613897\n",
      "accuracy 0.9496330887258172\n",
      "precision 0.9512585773084546\n",
      "recall 0.9496330887258172\n",
      "f1-score 0.945367259172423\n",
      "videoNr 3\n",
      "mae 27.823810168775434\n",
      "accuracy 0.922974324774925\n",
      "precision 0.9322564969839043\n",
      "recall 0.922974324774925\n",
      "f1-score 0.919946405939775\n",
      "videoNr 4\n",
      "mae 21.090738430553102\n",
      "accuracy 0.9213071023674558\n",
      "precision 0.9180632598331318\n",
      "recall 0.9213071023674558\n",
      "f1-score 0.9129561816212518\n",
      "videoNr 5\n",
      "mae 14.775912217404255\n",
      "accuracy 0.9789929976658887\n",
      "precision 0.9808043578252014\n",
      "recall 0.9789929976658887\n",
      "f1-score 0.9778143776658259\n",
      "videoNr 6\n",
      "mae 10.918877500743971\n",
      "accuracy 0.9823333333333333\n",
      "precision 0.9790990513116647\n",
      "recall 0.9823333333333333\n",
      "f1-score 0.9791172173324779\n",
      "Total\n",
      "mae 19.375545704035606\n",
      "accuracy 0.9495336924009631\n",
      "precision 0.9530054370986317\n",
      "recall 0.9495359306396932\n",
      "f1-score 0.9470787606653434\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "videoNrs = [1,2,3,4,5,6]\n",
    "xsplit = 45\n",
    "ysplit = 25\n",
    "printSingleVideos = True\n",
    "\n",
    "# Get mae, accuracy, precision, recall and F1-score for given videos\n",
    "mae, accuracy, precision, recall, f1 = evaluateVideos(videoNrs, xsplit, ysplit, printSingleVideos)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
